Metadata-Version: 2.4
Name: rammp
Version: 0.1.0
Summary: Code for RAMMP.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: pybullet_helpers @ git+https://github.com/Princeton-Robot-Planning-and-Learning/prpl-mono.git#subdirectory=pybullet-helpers
Requires-Dist: pyaudio
Requires-Dist: imageio[ffmpeg]
Requires-Dist: ruckig
Requires-Dist: relational_structs @ git+https://github.com/Princeton-Robot-Planning-and-Learning/prpl-mono.git#subdirectory=relational-structs
Requires-Dist: prpl-utils @ git+https://github.com/Princeton-Robot-Planning-and-Learning/prpl-mono.git#subdirectory=prpl-utils
Requires-Dist: tomsutils @ git+https://github.com/tomsilver/toms-utils.git
Requires-Dist: opencv-python
Requires-Dist: multiprocess
Requires-Dist: scikit-learn
Requires-Dist: scikit-image
Requires-Dist: yacs
Requires-Dist: kornia
Requires-Dist: chumpy
Requires-Dist: open3d
Requires-Dist: face-alignment
Requires-Dist: paramiko
Requires-Dist: numpy
Requires-Dist: defusedxml
Requires-Dist: twisted
Requires-Dist: pyOpenSSL
Requires-Dist: autobahn
Requires-Dist: tornado
Requires-Dist: bson
Requires-Dist: pyyaml
Requires-Dist: gTTS
Requires-Dist: playsound
Requires-Dist: rospkg
Requires-Dist: catkin_pkg
Requires-Dist: empy
Provides-Extra: develop
Requires-Dist: black; extra == "develop"
Requires-Dist: docformatter; extra == "develop"
Requires-Dist: isort; extra == "develop"
Requires-Dist: mypy; extra == "develop"
Requires-Dist: pylint>=2.14.5; extra == "develop"
Requires-Dist: pytest-pylint>=0.18.0; extra == "develop"
Requires-Dist: pytest>=7.2.2; extra == "develop"

## Requirements

- Python 3.10+
- Tested on Ubuntu 20.04

## Pre-Installation

1. Install ROS and rospy.
2. Install [pyaudio](https://pypi.org/project/PyAudio/).

## Installation

1. Recommended: create and source a virtualenv.
2. `pip install -e ".[develop]"`

## Run Feeding Demo on Real Robot
1. Run the arm controller server on the NUC:
   - ssh to the NUC: `sshnuc` with lab password
   - [only for inside-mouth bite transfer] zero the arm torque offsets:
        - Alias `set_zeros` on NUC
        - Otherwise, run the following commands:
             - `conda activate controller`
             - `cd ~/rammp/src/rammp/robot_controller`
             - `python kinova.py`
   - run the controller server:
        - Alias `run_server` on NUC
        - Otherwise, run the following commands:
             - `conda activate controller`
             - `cd rammp/src/rammp/robot_controller`
             - `python arm_server.py`
2. Run bulldog on the NUC:
   - ssh to the NUC: `sshnuc` with lab password
   - run bulldog with alias `run_bulldog`
2. Run a roscore on the compute system: `roscore`
3. Launch all the sensors on the compute system using `launch_sensors`
4. Launch the roslaunch on compute system for visualization / publish tfs / watchdog / transfer button:
   - Alias `launch_robot` on compute system
   - Otherwise,run the following commands from the root of your ROS workspace:
        - `conda activate feed`
        - `source devel/setup.bash`
        - `cd src/rammp/launch`
        - `roslaunch robot.launch`
5. Start the web application:
   - Make sure that the feeding laptop's WiFi is off (so that the webapp only launches on the router IP)
   - Alias `launch_app` on compute system
   - Run the following commands from the root of your ROS workspace:
        - `conda activate feed`
        - `source devel/setup.bash`
        - `cd ~/deployment_ws/src/feedingpage/vue-ros-demo`
        - `npm run serve`
   - On a browser connected to FeedingDeployment-5G (on the laptop or the iPad), open the following webpage: `http://192.168.1.2:8080/#/task_selection`
6. Start the IMU processing node:
   - `rosrun imu_filter_madgwick imu_filter_node   _use_mag:=false   _publish_tf:=false   /imu/data_raw:=/camera/imu`
8. Run the RAMMP demo:
   - Make sure that the feeding laptop's WiFi is on and connected to the internet so that ChatGPT API works (use KortexWiFi if available)
   - Run the following commands from the root of your ROS workspace:
        - `conda activate feed`
        - `source devel/setup.bash`
        - `cd src/rammp/src/rammp/integration`
        - `python run.py --user rammp --run_on_robot --no_waits --use_interface`
   - _Important Note 1:_ If you want to resume from some state (state names: after_utensil_pickup, after_bite_pickup, last_state), use: `python run.py --user rammp --run_on_robot --use_interface --no_waits --resume_from_state after_utensil_pickup` (replace after_utensil_pickup with appropriate state name).
   - _Important Note 2:_ The preset food item for `tests` user is bananas. If you want to try some other food item, just change the user name to a new one. For example, `python run.py --user tests_new --run_on_robot --use_interface --no_waits`

### Moving the robot to preset configurations

You can move the robot to preset configurations by running:
- Alias `cd_actions` on compute system
- `python retract.py` (you can also send it to transfer.py and acquisition.py) 

### Calibrate tool offset for inside-mouth transfer

1. Grasp the tool and move to before bite transfer position.
2. Calibrate tool:
   - Alias `cd_demo` on compute system
   - Otherwise, run the following commands from the root of your ROS workspace:
        - `conda activate feed`
        - `source devel/setup.bash`
        - `cd src/rammp/src/rammp/integration`
   - `python transfer_calibration.py --tool <tool_name>` where <tool_name> is one of "fork", "drink" and "wipe"
3. Manually (using buttons on the robot) move the robot to the intended inside-mouth transfer config, and press [ENTER] in the script above to record it. 
4. To test the tool calibration:
   - Alias `cd_demo` on compute system
   - Otherwise, run the following commands from the root of your ROS workspace:
        - `conda activate feed`
        - `source devel/setup.bash`
        - `cd src/rammp/src/rammp/integration` 
   - `python transfer_calibration.py --tool <tool_name> --test` where <tool_name> is one of "fork", "drink" and "wipe"
  
## Run Feeding Demo in Simulation
1. Launch the roslaunch for visualization / publish tfs:
   - Navigate to the launch files: `cd launch`
   - Launch: `roslaunch sim.launch`
2. Run the feeding demo:
   - Navigate to integration scripts: `cd src/rammp/integration`
   - Run demo: `python demo.py`

## Random

- To check FT readings: `rostopic echo /forque/forqueSensor`
- IP for robot: 192.168..10
- IP for webapp: `http://192.168.1.2:8080/#/task_selection`

## Check Installation

Run `./run_ci_checks.sh`. It should complete with all green successes in 5-10 seconds.
